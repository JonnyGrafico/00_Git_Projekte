{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrahieren von Text zum Social Media Archiv \n",
    "- https://democrats-intelligence.house.gov/social-media-content/\n",
    "- ```pip install progressbar```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit einer Datei ausprobieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Einleseversuch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Ad ID  374  Ad Text  Join us because we care. Black matters.  Ad Landing Page  https://www.facebook.com/Black-Matters-1579673598947501 /  Ad Targeting  Location: United States: Baltimore (+20 km) Maryland; St. Louis (+20 km) Missouri Excluded Connections: Exclude people who like Black Matters Age: 18 - 65+ Language: English (UK) or English (US) Placements: News Feed on desktop computers or News Feed on mobile devices  Ad Impressions  137  Ad Clicks  0  Ad Spend  44.87 RUB  Ad Creation Date  06/10/15 02:59:53 AM PDT  P(1)0000054  Redactions Completed at the Direction of Ranking Member of the US House Permanent Select Committee on Intelligence\\\\x0cSuggested Page  Black Matters Sponsored  Join us because we care. Black matters.  Black Matters Commun,ty 224,537 people like  nis.  ,` Like Page  P(1)0000055  Redactions Completed at the Direction of Ranking Member of the US House Permanent Select Committee on Intelligence\\\\x0c'\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing with one file\n",
    "text = textract.process('files/P(1)0000054.pdf', method='pdfminer')\n",
    "text = str(text).replace(\"\\n\\n\", \" \")\n",
    "text = str(text).replace(\"\\n\", \" \")\n",
    "text = str(text).replace(\"\\\\n\", \" \")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suchen nach dem Adtext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Join us because we care. Black matters.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adtext = re.search(\"Ad Text.*Ad Landing Page\", text)\n",
    "adtext = re.search(\"Ad Text.*Ad Landing Page\", text).group().replace(\"Ad Landing Page\", \"\")\n",
    "adtext = adtext.replace(\"Ad Text\", \"\").replace(\"\\\\n\", \" \").strip()\n",
    "adtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Location: United States: Baltimore (+20 km) Maryland; St. Louis (+20 km) Missouri Excluded Connections: Exclude people who like Black Matters '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_location(text):\n",
    "    if re.search(\"Location.*(Age)\", text) != None:\n",
    "        pattern = re.search(\"Location.*(Age)\", text)\n",
    "        loc = pattern.group().replace('Age','').replace('Location - Living In: ','')\n",
    "    else:\n",
    "        loc = 'N/A'\n",
    "    return loc\n",
    "get_location(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06/10/15 02:59:53 AM PDT'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date(text):\n",
    "    if re.search(\"Creation Date.*(Redactions)\", str(text)) != None:\n",
    "        pattern = re.search(\"Creation Date.*(Redactions)\", str(text))\n",
    "        pattern = pattern.group().replace('Creation Date\\\\n\\\\n','')\n",
    "        date = re.search(\"\\d\\d/\\d\\d/\\d\\d \\d\\d:\\d\\d:\\d\\d [A-Z][A-Z] [A-Z]{3}\", pattern)\n",
    "        if date != None:\n",
    "            date = date.group()\n",
    "    else: \n",
    "        date = 'N/A'\n",
    "    return date\n",
    "get_date(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ad_klicks(text):\n",
    "    if re.search(\"Ad Clicks.*\", text) != None:\n",
    "        klicks = re.search(\"Ad Clicks.*\", text)\n",
    "        klicks = klicks.group()[:25].replace(\",\", \"\")\n",
    "        klicks = re.search(\"[0-9]+\", klicks)\n",
    "        if klicks != None:\n",
    "            klicks = klicks.group()\n",
    "    else:\n",
    "        klicks = 'N/A'\n",
    "    return klicks\n",
    "get_ad_klicks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'137'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ad_impressions(text):\n",
    "    if re.search(\"Ad Impressions.*\", text) != None:\n",
    "        imps = re.search(\"Ad Impressions.*\", text)\n",
    "        imps = imps.group()[:25].replace(\",\", \"\")\n",
    "        imps = re.search(\"[0-9]+\", imps)\n",
    "        if imps != None:\n",
    "            imps = imps.group()\n",
    "    else:\n",
    "        imps = 'N/A'\n",
    "    return imps\n",
    "get_ad_impressions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44.87'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ad_spend(text):\n",
    "    if re.search(\"Ad Spend.*\", text) != None:\n",
    "        adspend = re.search(\"Ad Spend.*\", text)\n",
    "        adspend = adspend.group()[:25].replace(\",\", \"\")\n",
    "        adspend = re.search(\"[0-9]+.[0-9]+\", adspend)\n",
    "        if adspend != None:\n",
    "            adspend = adspend.group()\n",
    "    else:\n",
    "        adspend = 'N/A'\n",
    "    return adspend\n",
    "get_ad_spend(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau der Dateiliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 Importing Text from Everywhere.ipynb\r\n",
      "2.2 Real world example with textract.ipynb\r\n",
      "2.3 Named Entities Recognition.ipynb\r\n",
      "2.4 Classifying Text.ipynb\r\n",
      "2.5 OpenCV - Gesichtserkennung.ipynb\r\n",
      "2.6 Document Similarity with TDF-IDF.ipynb\r\n",
      "2.7 [OPTIONAL] Similar Words and Sentences with spaCy.ipynb\r\n",
      "2.8 [OPTIONAL] Objekterkennung as a service mit IBM Vision.ipynb\r\n",
      "2.9 [OPTIONAL] Sentiment, Spracherkennung, Spellchecking.ipynb\r\n",
      "bild.jpg\r\n",
      "example.docx\r\n",
      "example.pdf\r\n",
      "example.png\r\n",
      "\u001b[34mfiles\u001b[m\u001b[m\r\n",
      "fruitbowl.jpg\r\n",
      "godfather.txt\r\n",
      "guardian.png\r\n",
      "\u001b[34mhaarcascades\u001b[m\u001b[m\r\n",
      "\u001b[34minstagram\u001b[m\u001b[m\r\n",
      "obama.txt\r\n",
      "readable.csv\r\n",
      "schindlers_list.txt\r\n",
      "shawnshank.txt\r\n",
      "\u001b[34msongtexte\u001b[m\u001b[m\r\n",
      "tf-idf.jpeg\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating file list\n",
    "lt = sorted(os.listdir(\"files\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for elem in lt:\n",
    "    if \".pdf\" in elem:\n",
    "        lst.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst = lst[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "#Creating dictionary for:\n",
    "\n",
    "#'Location', 'Number', 'Date', 'Interests',\n",
    "#'Age', 'Language', 'Placements', 'Ad Clicks',\n",
    "#'Ad Impressions', 'Ad Spend'\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "results = []\n",
    "\n",
    "for elem,i in zip(lst, bar(range(len(lst)-1))):\n",
    "    #print(elem)\n",
    "    if 'ultimate_names.csv' in elem:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        text = textract.process('files/'+elem, method='pdfminer')\n",
    "        text = str(text).replace(\"\\n\\n\", \" \")\n",
    "        text = str(text).replace(\"\\n\", \" \")\n",
    "\n",
    "    \n",
    "        location = get_location(text)\n",
    "        date = get_date(text)\n",
    "        klicks = get_ad_klicks(text)\n",
    "        imps = get_ad_impressions(text)\n",
    "        adspend = get_ad_spend(text)\n",
    "\n",
    "        \n",
    "        mini_dict = {'Location': location,\n",
    "                 'Number': elem,\n",
    "                 'Date': date,\n",
    "                 'Interests': interests,\n",
    "                 'Age': age,\n",
    "                 'Language': lang,\n",
    "                 'Placements': place,\n",
    "                 'Ad Text': adtext,\n",
    "                 'Ad Clicks': klicks,\n",
    "                 'Ad Impressions': imps,\n",
    "                 'Ad Spend': adspend}\n",
    "        \n",
    "        results.append(mini_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version von Barney mit if else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "#Creating dictionary for:\n",
    "\n",
    "#'Location', 'Number', 'Date', 'Interests',\n",
    "#'Age', 'Language', 'Placements', 'Ad Clicks',\n",
    "#'Ad Impressions', 'Ad Spend'\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "results = []\n",
    "\n",
    "for elem,i in zip(lst, bar(range(len(lst)-1))):\n",
    "    #print(elem)\n",
    "    if 'ultimate_names.csv' in elem:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        text = textract.process('files/'+elem, method='pdfminer')\n",
    "        text = str(text).replace(\"\\n\\n\", \" \")\n",
    "        text = str(text).replace(\"\\n\", \" \")\n",
    "\n",
    "        \n",
    "        \n",
    "        if re.search(\"Interests:.*\", text) != None:\n",
    "            interests = re.search(\"Interests:.*\", text).group().split('\\\\n')[0]\n",
    "        else:\n",
    "            interests = 'N/A'\n",
    "    \n",
    "        if re.search(\"Age:.*\", text) != None:\n",
    "            age = re.search(\"Age:.*\", text).group().split('\\\\n')[0]\n",
    "        else:\n",
    "            age = 'N/A'\n",
    "        \n",
    "        if re.search(\"Language:.*\", text) != None:\n",
    "            lang = re.search(\"Language:.*\", text).group().split('\\\\n')[0]\n",
    "        else:\n",
    "            lang = 'N/A'\n",
    "    \n",
    "        if re.search(\"Placements:.*\", text) != None:\n",
    "            place = re.search(\"Placements:.*\", text).group().split('\\\\n')[0]\n",
    "        else:\n",
    "            place = 'N/A'\n",
    "    \n",
    "        if re.search(\"Ad Text.*Ad Landing Page\", text) != None:\n",
    "            adtext = re.search(\"Ad Text.*Ad Landing Page\", text).group().replace(\"Ad Landing Page\", \"\")\n",
    "            adtext = adtext.replace(\"Ad Text\", \"\").replace(\"\\\\n\", \" \").strip()\n",
    "        else:\n",
    "            place = 'N/A'\n",
    "        \n",
    "        mini_dict = {'Location': location,\n",
    "                 'Number': elem,\n",
    "                 'Date': date,\n",
    "                 'Interests': interests,\n",
    "                 'Age': age,\n",
    "                 'Language': lang,\n",
    "                 'Placements': place,\n",
    "                 'Ad Text': adtext,\n",
    "                 'Ad Clicks': klicks,\n",
    "                 'Ad Impressions': imps,\n",
    "                 'Ad Spend': adspend}\n",
    "        \n",
    "        results.append(mini_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abspeichern im Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abspeichern als CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('readable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
